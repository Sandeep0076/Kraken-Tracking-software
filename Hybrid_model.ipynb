{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Hybrid-model",
      "provenance": [],
      "collapsed_sections": [
        "w_t89SR2lFKy",
        "p3FjTxP5lNc3",
        "cInLjRhStUKA"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73f92d1ba15d441ea8f04647d446a5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53db8bb00f3f4443ac716e0ae59014a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9bfd3a38652c4cc385cb12486d85cf05",
              "IPY_MODEL_d7a7ede64be947a599b396d61207b4da"
            ]
          }
        },
        "53db8bb00f3f4443ac716e0ae59014a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bfd3a38652c4cc385cb12486d85cf05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_28584ece32fe4a7faba766f28dd8cb8a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fea9648045d4cc999f35b3c39adaaaa"
          }
        },
        "d7a7ede64be947a599b396d61207b4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8741d755a4744fbe8e24dc86cecc89c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 305kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1cbf17f018aa4007a50619af622046e6"
          }
        },
        "28584ece32fe4a7faba766f28dd8cb8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fea9648045d4cc999f35b3c39adaaaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8741d755a4744fbe8e24dc86cecc89c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1cbf17f018aa4007a50619af622046e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandeep0076/Project/blob/master/Hybrid_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_t89SR2lFKy"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJlOuLW_jSQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5733b3f-4299-4e4e-a840-802b3ce8236c"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/Gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/Gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhxC5T8cjwxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6dafa3-d21d-4c78-cf1d-5d015bb1df27"
      },
      "source": [
        "!pip install transformers~=3.4.0\n",
        "!pip install boilerpy3\n",
        "#!pip install transformers\n",
        "#pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers~=3.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 5.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers~=3.4.0) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers~=3.4.0) (2.23.0)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/e7/edf655ae34925aeaefb7b7fcc3dd0887d2a1203ee6b0df4d1170d1a19d4f/tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers~=3.4.0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers~=3.4.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers~=3.4.0) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers~=3.4.0) (3.0.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers~=3.4.0) (3.12.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers~=3.4.0) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=3.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=3.4.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=3.4.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=3.4.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=3.4.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=3.4.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers~=3.4.0) (54.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=dc868bff4aa69038c466d34275840b7982eb22d5e0b8bd6895a402e7ec8b92f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.9.2 transformers-3.4.0\n",
            "Collecting boilerpy3\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/c1/aa6b2ab42a3678892de45fac2b1f4bbc326af1559214bfc563b5e0ef78b2/boilerpy3-1.0.4-py3-none-any.whl\n",
            "Installing collected packages: boilerpy3\n",
            "Successfully installed boilerpy3-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEAt-VGTjsOg"
      },
      "source": [
        "\"\"\"## Imports\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support as score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,Dataset,random_split,SubsetRandomSampler\n",
        "\n",
        "import transformers\n",
        "from transformers import  BertTokenizer, RobertaModel, BertModel, AdamW, AutoConfig,get_linear_schedule_with_warmup\n",
        "\n",
        "import time \n",
        "from datetime import  date\n",
        "import warnings\n",
        "import collections \n",
        "from operator import truediv\n",
        "from boilerpy3 import extractors\n",
        "from urllib.parse import quote,unquote,urlparse\n",
        "from urllib.request import urlopen\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxIKHzFYyA_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6711e7d-fbae-4c25-b319-54eab8340ce2"
      },
      "source": [
        "print(f'sklearn version : {sklearn.__version__}')\n",
        "print(f'torch version : {torch.__version__}')\n",
        "print(f'transformer version : {transformers.__version__}')\n",
        "print(f'pandas version : {pd.__version__}')\n",
        "print(f'numpy version : {np.__version__}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sklearn version : 0.22.2.post1\n",
            "torch version : 1.8.0+cu101\n",
            "transformer version : 3.4.0\n",
            "pandas version : 1.1.5\n",
            "numpy version : 1.19.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98xdC7mA8P9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5204a1eb-f96d-4b5d-d0cf-b51fde96dd1c"
      },
      "source": [
        "'''\n",
        "def stratify_train_test(df, stratifyby, *args, **kwargs):\n",
        "    train, test = pd.DataFrame(), pd.DataFrame()\n",
        "    gb = df.groupby(stratifyby)\n",
        "    for k in gb.groups:\n",
        "        traink, testk = train_test_split(gb.get_group(k), *args, **kwargs)\n",
        "        train = pd.concat([train, traink])\n",
        "        test = pd.concat([test, testk])\n",
        "    return train, test\n",
        "\n",
        "train, test = stratify_train_test(df1, 'label', test_size=.20)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef stratify_train_test(df, stratifyby, *args, **kwargs):\\n    train, test = pd.DataFrame(), pd.DataFrame()\\n    gb = df.groupby(stratifyby)\\n    for k in gb.groups:\\n        traink, testk = train_test_split(gb.get_group(k), *args, **kwargs)\\n        train = pd.concat([train, traink])\\n        test = pd.concat([test, testk])\\n    return train, test\\n\\ntrain, test = stratify_train_test(df1, 'label', test_size=.20)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QerT-IrMWHrX"
      },
      "source": [
        "sklearn version : 0.22.2.post1\n",
        "torch version : 1.7.0+cu101\n",
        "transformer version : 3.4.0\n",
        "pandas version : 1.1.4\n",
        "numpy version : 1.18.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3FjTxP5lNc3"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTOj98WoioAt",
        "outputId": "1fb8626b-8881-47a6-ba94-5ecb802666d4"
      },
      "source": [
        "# Base bert class for training and classification of the model\n",
        "class Bert_TextClassification_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bert_TextClassification_Model, self).__init__()\n",
        "        self.num_classes = NUM_CLASSES\n",
        "        self.bert_path = 'bert-base-uncased'\n",
        "        # Adding Gradient checkpoint for reducing memory usage\n",
        "        #it is saving 50% of memory in my case before the Model was going out of memory even with 11Gb now\n",
        "        #now after deleting unused variable, checkpointing and smaller variables consuption is reduced to 4Gb\n",
        "        self.config = AutoConfig.from_pretrained(self.bert_path,\n",
        "                                                 gradient_checkpointing=True,\n",
        "                                                 attention_probs_dropout_prob=0.5,\n",
        "                                                 hidden_dropout_prob=0.5\n",
        "                                                  )\n",
        "        #for memory conservation by using smaller value\n",
        "        self.config.use_bfloat16 = True\n",
        "        self.bert = transformers.BertModel.from_pretrained(self.bert_path, config=self.config)\n",
        "        #added a new dropout \n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.out = nn.Linear(768, self.num_classes)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, pooled_out = self.bert(\n",
        "            ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "        #added a new dropout \n",
        "        pooled_out = self.dropout(pooled_out)\n",
        "        return self.out(pooled_out)\n",
        "\n",
        "# This implements Bert take out the fined tuned model excluding last and add LSTM and linear layer on top of it to achieve higher accuracy\n",
        "class RoBERT_Model(nn.Module):\n",
        "\n",
        "    def __init__(self, bertFineTuned):\n",
        "        super(RoBERT_Model, self).__init__()\n",
        "        self.num_classes = NUM_CLASSES\n",
        "        # old model is initialized which is trained and remembers the weights and bais.\n",
        "        # since bert model only take 512 we will input the data with the same order\n",
        "        # but before we feed to the lstm layer,we will combine the output of bert which was previously\n",
        "        # divided into 200, seg and then in last filter out in linear\n",
        "        self.bertFineTuned = bertFineTuned\n",
        "        self.lstm = nn.LSTM(768, 100, num_layers=1, bidirectional=False)\n",
        "        #added a new dropout \n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(100, self.num_classes)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids, num_chunks):\n",
        "        _, pooled_out = self.bertFineTuned(ids,\n",
        "                                           attention_mask=mask,\n",
        "                                           token_type_ids=token_type_ids)\n",
        "\n",
        "        #For every 200-lenght chunk we extracted a representation vector from BERT of size 768 each\n",
        "        #which is the size of the hidden layer\n",
        "        chunks_emb = pooled_out.split_with_sizes(num_chunks)\n",
        "        #print(f'Number of chunks : {num_chunks}')\n",
        "\n",
        "        seq_num_chunkshs = torch.LongTensor([x for x in map(len, chunks_emb)])\n",
        "        #seq_len = tensor(5) for 5 chunks in a document\n",
        "        del pooled_out\n",
        "        #  number of 200-num_chunksh chunk is not fixed\n",
        "        #Pad a list of variable num_chunksh Tensors with padding_value\n",
        "        #sequences (list[Tensor]) â€“ list of variable num_chunksh sequences.\n",
        "        #batch_first (bool, optional) â€“ output will be in B x T x * if True, or in T x B x * otherwise\n",
        "        #padding_value (float, optional) â€“ value for padded elements. Default: 0.\n",
        "        #* is any number of trailing dimensions\n",
        "        '''\n",
        "        , batch size more than one,padding to the max num_chunksh and masking, \n",
        "        in this way we pad the shorter sequences with a special value to be masked (skipped for the network) later.\n",
        "        In this case the special values is -99\n",
        "        '''\n",
        "        # batch_emb_pad = [1,5,768]\n",
        "        batch_emb_pad = nn.utils.rnn.pad_sequence(chunks_emb,\n",
        "                                                  padding_value=-99,\n",
        "                                                  batch_first=True)\n",
        "        # batch_emb = [5,1,768]\n",
        "        batch_emb = batch_emb_pad.transpose(0, 1)  # (B,L,D) -> (L,B,D)\n",
        "\n",
        "        #Packs a Tensor containing padded sequences  from above of variable num_chunksh.\n",
        "        # because each document can be of different len\n",
        "        lstm_input = nn.utils.rnn.pack_padded_sequence(batch_emb, seq_num_chunkshs.cpu().numpy(),\n",
        "                                                       batch_first=False, enforce_sorted=False)\n",
        "        # lstm_input Bactch size is [1,1,1,1,1] meaning 5\n",
        "        #this will reduce it to 100 layers  as initiatized\n",
        "        #packed_output = 100*5() 5 is batch\n",
        "        #h_t = 100 is a  output vector of output shape [1,1,100]\n",
        "        packed_output, (h_t, h_c) = self.lstm(lstm_input, )  # (h_t, h_c))\n",
        "\n",
        "        h_t = h_t.view(-1, 100)\n",
        "        #added dropout\n",
        "        h_t = self.dropout(h_t)\n",
        "\n",
        "\n",
        "        return self.out(h_t)\n",
        "\n",
        "# Train and Evaluate - Bert Model\n",
        "def train_eval_bert_model(data_loader, model, optimizer, device, mode, scheduler=None):\n",
        "    target_res = []\n",
        "    output_res = []\n",
        "    if mode=='train':\n",
        "        model.train()\n",
        "        t0 = time.time()\n",
        "    elif mode=='eval':\n",
        "        model.eval()\n",
        "\n",
        "    else:\n",
        "        print('wrong mode given')\n",
        "\n",
        "    losses = []\n",
        "    for batch_idx, batch in enumerate(data_loader):\n",
        "\n",
        "        # taking out the data from dataloader\n",
        "        ids = [data[\"ids\"] for data in batch]\n",
        "        # This will give list of tensor ids,masks....\n",
        "        mask = [data[\"mask\"] for data in batch]\n",
        "        token_type_ids = [data[\"token_type_ids\"] for data in batch]\n",
        "        targets = [data[\"targets\"] for data in batch]\n",
        "        # [tensor([1, 1, 1], dtype=torch.int32)]<class 'list'>\n",
        "        num_chunks = [data['len'] for data in batch]\n",
        "        #\toutput is [tensor([3])]<class 'list'>\n",
        "\n",
        "        # Converting list into tensors\n",
        "        ids = torch.cat(ids)\n",
        "        mask = torch.cat(mask)\n",
        "        token_type_ids = torch.cat(token_type_ids)\n",
        "        targets = torch.cat(targets)\n",
        "        # tensor([1, 1, 1], dtype=torch.int32)<class 'torch.Tensor'>\n",
        "        num_chunks = torch.cat(num_chunks)\n",
        "        # output is tensor([3])<class 'torch.Tensor'>\n",
        "\n",
        "        # Loading variables to Memory\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.long)\n",
        "\n",
        "        if mode=='train':\n",
        "            # changing all the previous gradients to zero if any\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "\n",
        "            # Deleting unused variables which consume quite a bit of memory\n",
        "            del ids, mask, token_type_ids, num_chunks\n",
        "\n",
        "            loss = loss_fun(outputs, targets)\n",
        "            loss.backward()\n",
        "            model.float()\n",
        "            optimizer.step()\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "            losses.append(loss.item())\n",
        "            del loss\n",
        "            if batch_idx % 1000 == 0:\n",
        "                print(\n",
        "                    f\"batch index = {batch_idx} / {len(data_loader)} ({100 * batch_idx / len(data_loader):.2f}%), loss = {np.mean(losses[-10:]):.4f}, time = {(time.time()-t0)//60} minutes \")\n",
        "                t0 = time.time()\n",
        "            output = losses\n",
        "\n",
        "        elif mode =='eval':\n",
        "            with torch.no_grad():\n",
        "                outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "                del ids, mask, token_type_ids, num_chunks\n",
        "                loss = loss_fun(outputs, targets)\n",
        "                losses.append(loss.item())\n",
        "                del loss\n",
        "\n",
        "            \n",
        "            target_res.append(targets.cpu().detach().numpy())\n",
        "            output_res.append(torch.softmax(outputs, dim=1).cpu().detach().numpy())\n",
        "            output = np.concatenate(output_res), np.concatenate(target_res), losses\n",
        "\n",
        "    return  output\n",
        "\n",
        "# Train and Evaluate - RoBert Model\n",
        "def train_eval_robert_model(data_loader, model, optimizer, device, mode, scheduler=None):\n",
        "    target_res = []\n",
        "    output_res = []\n",
        "    if mode == 'train':\n",
        "        model.train()\n",
        "        t0 = time.time()\n",
        "    elif mode == 'eval':\n",
        "        model.eval()\n",
        "    else:\n",
        "        print('wrong mode given')\n",
        "\n",
        "    losses = []\n",
        "    for batch_idx, batch in enumerate(data_loader):\n",
        "\n",
        "        # taking out the data from dataloader\n",
        "        ids = [data[\"ids\"] for data in batch]\n",
        "        mask = [data[\"mask\"] for data in batch]\n",
        "        token_type_ids = [data[\"token_type_ids\"] for data in batch]\n",
        "        targets = [data[\"targets\"][0] for data in batch]\n",
        "        num_chunks = [data['len'] for data in batch]\n",
        "        # input is <class 'list'>\n",
        "        # targets and its type : [tensor(0, dtype=torch.int32)]<class 'list'>\n",
        "        # num_chunks and its type : [tensor([5])]<class 'list'>\n",
        "        ids = torch.cat(ids)\n",
        "        mask = torch.cat(mask)\n",
        "        token_type_ids = torch.cat(token_type_ids)\n",
        "        targets = torch.stack(targets)\n",
        "        num_chunks = torch.cat(num_chunks)\n",
        "        num_chunks = [x.item() for x in num_chunks]\n",
        "        # stacked targets and its type : tensor([0], dtype=torch.int32)<class 'torch.Tensor'>\n",
        "        # concatenated num_chunks and its type : tensor([5])<class 'torch.Tensor'>\n",
        "        # ietms num_chunks and its type : [5]<class 'list'>\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.long)\n",
        "\n",
        "        if mode == 'train':\n",
        "            # changing all the previous gradients to zero if any\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(ids=ids, mask=mask,\n",
        "                            token_type_ids=token_type_ids, num_chunks=num_chunks)\n",
        "            del ids, mask, token_type_ids, num_chunks\n",
        "            loss = loss_fun(outputs, targets)\n",
        "            loss.backward()\n",
        "            model.float()\n",
        "            optimizer.step()\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "            losses.append(loss.item())\n",
        "            del loss\n",
        "            if batch_idx % 1000 == 0:\n",
        "              print(\n",
        "                f\"batch index = {batch_idx} / {len(data_loader)} ({100*batch_idx / len(data_loader):.2f}%), loss = {np.mean(losses[-10:]):.4f}, time = {(time.time()-t0)//60} minutes\")\n",
        "              t0 = time.time()\n",
        "            target_res.append(targets.cpu().detach().numpy())\n",
        "            output_res.append(torch.softmax(\n",
        "                outputs, dim=1).cpu().detach().numpy())\n",
        "            output = np.concatenate(output_res), np.concatenate(target_res), losses\n",
        "\n",
        "        elif mode == 'eval':\n",
        "            with torch.no_grad():\n",
        "                outputs = model(ids=ids, mask=mask,\n",
        "                                token_type_ids=token_type_ids, num_chunks=num_chunks)\n",
        "                loss = loss_fun(outputs, targets)\n",
        "                losses.append(loss.item())\n",
        "            target_res.append(targets.cpu().detach().numpy())\n",
        "            output_res.append(torch.softmax(\n",
        "                outputs, dim=1).cpu().detach().numpy())\n",
        "            output = np.concatenate(output_res), np.concatenate(target_res), losses\n",
        "\n",
        "    return output\n",
        "\n",
        "# To create a dataloader with variable-size input\n",
        "def my_collate1(batches):\n",
        "    return [{key: torch.stack(value) for key, value in batch.items()} for batch in batches]\n",
        "\n",
        "# Loss function\n",
        "def loss_fun(outputs, targets):\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    return loss(outputs, targets)\n",
        "    # return nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "# For predictions and accuracy\n",
        "def evaluate(target, predicted):\n",
        "    true_label_mask = [1 if (np.argmax(x) - target[i]) ==\n",
        "                            0 else 0 for i, x in enumerate(predicted)]\n",
        "    nb_prediction = len(true_label_mask)\n",
        "    true_prediction = sum(true_label_mask)\n",
        "    false_prediction = nb_prediction - true_prediction\n",
        "    Accuracy = true_prediction / nb_prediction\n",
        "    return {\n",
        "        \"Accuracy\": Accuracy,\n",
        "        \"No. of examples\": len(target),\n",
        "        \"True prediction\": true_prediction,\n",
        "        \"False prediction\": false_prediction,\n",
        "    }\n",
        "#----------------------------------------------\n",
        "# can join evaluate and f1 score and remove accuracy \n",
        "\n",
        "# Precision () is defined as the number of true positives () over \n",
        "# the number of true positives plus the number of false positives \n",
        "def get_f1_precision_recall(y_test,y_pred):\n",
        "    \n",
        "  float_formatter = \"{:.2f}\".format\n",
        "  np.set_printoptions(formatter={'float_kind':float_formatter})\n",
        "\n",
        "  precision, recall, fscore, support = score(y_test, y_pred)\n",
        "  print('precision: {}'.format(precision))\n",
        "  print('recall   : {}'.format(recall))\n",
        "  print('fscore   : {}'.format(fscore))\n",
        "  return\n",
        "\n",
        "# For plotting confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    import itertools\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "# To create, clean and divide the dataset into chunks\n",
        "class FakeNewsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, max_len, chunk_len=200, overlap_len=50, max_size_dataset=None,\n",
        "                  file_location=None, min_len=10, mode='train_eval', testdf=None):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.overlap_len = overlap_len\n",
        "        self.chunk_len = chunk_len\n",
        "        self.min_len = min_len\n",
        "        self.max_size_dataset = max_size_dataset\n",
        "        self.testdf = testdf\n",
        "        self.mode = mode\n",
        "        self.data, self.label,self.label_count,self.label_mapping= self.process_data(file_location,mode,testdf )\n",
        "\n",
        "    def process_data(self,file_location,mode,testdf):\n",
        "        \n",
        "        base_l = []\n",
        "        # dataset for training and evaluation\n",
        "        if mode == 'train_eval':\n",
        "          df = pd.read_csv(file_location)\n",
        "          train_raw = df[df.body.notnull()]\n",
        "          train_raw = train_raw[train_raw.title.notnull()]\n",
        "        # dataset for predicting the single outcome\n",
        "        elif mode == 'test':\n",
        "          train_raw = testdf.copy()\n",
        "\n",
        "        \n",
        "        base_l = get_base_url (train_raw.url)\n",
        "        train_raw['base_url'] = base_l\n",
        "        train_raw = train_raw.assign(len_txt=train_raw.body.apply(lambda x: len(x.split())))\n",
        "        train_raw = train_raw[train_raw.len_txt > self.min_len]\n",
        "\n",
        "        train_raw = train_raw[['title','body', 'label','base_url']]\n",
        "        train_raw.reset_index(inplace=True, drop=True)        \n",
        "        train = train_raw.copy()\n",
        "        del train_raw\n",
        "        if (self.max_size_dataset):\n",
        "            train = train.loc[0:self.max_size_dataset, :]\n",
        "        train = train.reindex(np.random.permutation(train.index))\n",
        "      \n",
        "        train['body'] = train.body.apply(self.clean_txt)\n",
        "        train['title'] = train.title.apply(self.clean_txt)\n",
        "        train['text'] = train[['title','body']].agg(' '.join, axis=1)\n",
        "\n",
        "        label_count = train['label'].value_counts()\n",
        "        LE = LabelEncoder()\n",
        "        train['label'] = LE.fit_transform(train['label'])\n",
        "        label_mapping = dict(zip(LE.classes_, range(len(LE.classes_))))\n",
        "\n",
        "        return train['text'].values, train['label'].values,label_count,label_mapping\n",
        "\n",
        "    def clean_txt(self, text):\n",
        "        # Apply regex and clean the data\n",
        "        text = re.sub(\"'\", \"\", text)\n",
        "        text = re.sub(\"the\", \"\", text)\n",
        "        text = re.sub(\"The\", \"\", text)\n",
        "        text = re.sub(\"(\\\\W)+\", \" \", text)\n",
        "        text = re.sub(r'[^A-Z-a-z. \\d/,]', '', text.lower())\n",
        "        text = ' '.join(text.split())\n",
        "        return text\n",
        "\n",
        "    def long_terms_tokenizer(self, data_tokenize, targets):\n",
        "        \n",
        "        input_ids_list = []\n",
        "        attention_mask_list = []\n",
        "        token_type_ids_list = []\n",
        "        targets_list = []\n",
        "\n",
        "        previous_input_ids = data_tokenize[\"input_ids\"].reshape(-1)\n",
        "        previous_attention_mask = data_tokenize[\"attention_mask\"].reshape(-1)\n",
        "        previous_token_type_ids = data_tokenize[\"token_type_ids\"].reshape(-1)\n",
        "\n",
        "        # it contains tokens that are after 200 num_chunksh because of CHUNK_LEN=200\n",
        "        overflowing_ids = data_tokenize.get(\"overflowing_tokens\").reshape(-1)  # added .reshape(-1)\n",
        "        targets = torch.tensor(targets, dtype=torch.int)\n",
        "\n",
        "        input_ids_list.append(previous_input_ids)\n",
        "        attention_mask_list.append(previous_attention_mask)\n",
        "        token_type_ids_list.append(previous_token_type_ids)\n",
        "        targets_list.append(targets)\n",
        "\n",
        "        if overflowing_ids.nelement() != 0 :\n",
        "            overflowing_ids = torch.tensor(overflowing_ids, dtype=torch.long)\n",
        "            # total no. of index, chunck + overflow\n",
        "            # range means how many steps of 200 chunks eg if len is 723, then range is 4\n",
        "            idxs = range(len(overflowing_ids) + self.chunk_len)\n",
        "            # from where the next chunk starts\n",
        "            # idxs = start, step, stop, 148,148,396\n",
        "            idxs = idxs[(self.chunk_len - self.overlap_len - 2)\n",
        "                        ::(self.chunk_len - self.overlap_len - 2)]\n",
        "            # input_ids_first_overlap last 50 tokens of the first 200 batch\n",
        "            input_ids_first_overlap = previous_input_ids[-(\n",
        "                    self.overlap_len + 1):-1]\n",
        "            start_token = torch.tensor([101], dtype=torch.long)\n",
        "            end_token = torch.tensor([102], dtype=torch.long)\n",
        "\n",
        "            for i, idx in enumerate(idxs):\n",
        "                # enumerate i = counter, 1,2 3--\n",
        "                if i == 0:\n",
        "                    # input_ids = 50 from last of the first batch + 148 from overflowing_ids + 2 tokens\n",
        "                    input_ids = torch.cat(\n",
        "                        (input_ids_first_overlap, overflowing_ids[:idx]))\n",
        "                elif i == len(idxs):\n",
        "                    # for the last overflowing_idsing indexes\n",
        "                    input_ids = overflowing_ids[idx:]\n",
        "                elif previous_idx >= len(overflowing_ids):\n",
        "                    # when the indexes finishes it breaks\n",
        "                    break\n",
        "                else:\n",
        "                    # if not the first and the last, in between then last index-50, to overlap till next 150\n",
        "                    input_ids = overflowing_ids[(previous_idx - self.overlap_len):idx]\n",
        "\n",
        "                previous_idx = idx\n",
        "\n",
        "                # after getting input ids add equivalant amount of attention mask and then token ids\n",
        "                nb_token = len(input_ids) + 2\n",
        "                attention_mask = torch.ones(self.chunk_len, dtype=torch.long)  # chunk len = 200\n",
        "                attention_mask[nb_token:self.chunk_len] = 0\n",
        "                token_type_ids = torch.zeros(self.chunk_len, dtype=torch.long)\n",
        "                input_ids = torch.cat((start_token, input_ids, end_token))\n",
        "                # if its input id is less then 200, then add padding till 200\n",
        "                if self.chunk_len - nb_token > 0:\n",
        "                    padding = torch.zeros(\n",
        "                        self.chunk_len - nb_token, dtype=torch.long)\n",
        "                    input_ids = torch.cat((input_ids, padding))\n",
        "\n",
        "                input_ids_list.append(input_ids)\n",
        "                attention_mask_list.append(attention_mask)\n",
        "                token_type_ids_list.append(token_type_ids)\n",
        "                targets_list.append(targets)\n",
        "        return ({\n",
        "            'ids': input_ids_list,  # torch.tensor(ids, dtype=torch.long),\n",
        "            # torch.tensor(mask, dtype=torch.long),\n",
        "            'mask': attention_mask_list,\n",
        "            # torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'token_type_ids': token_type_ids_list,\n",
        "            'targets': targets_list,\n",
        "            'len': [torch.tensor(len(targets_list), dtype=torch.long)]\n",
        "        })\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        body = str(self.data[idx])\n",
        "        targets = int(self.label[idx])\n",
        "        data = self.tokenizer.encode_plus(\n",
        "            body,\n",
        "            truncation=True,\n",
        "            max_length=self.chunk_len,\n",
        "            padding='longest',\n",
        "            add_special_tokens=True,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_overflowing_tokens=True,\n",
        "            return_tensors='pt')\n",
        "        # calling third function\n",
        "        long_token = self.long_terms_tokenizer(data, targets)\n",
        "        return long_token\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Return data length \"\"\"\n",
        "        return self.label.shape[0]\n",
        "\n",
        "# For extracting base url from complete url\n",
        "def get_base_url (long_url):  \n",
        "  ls = []\n",
        "  for item in long_url:\n",
        "      u=unquote(item)\n",
        "      g=urlparse(u)\n",
        "      base_url=g.netloc\n",
        "      ls.append(base_url)\n",
        "  return ls\n",
        "\n",
        "# For extracting article from the URL \n",
        "def get_text_from_url(url):\n",
        "  try:\n",
        "    extractor = extractors.ArticleExtractor()\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'\n",
        "    }\n",
        "    resp = requests.get(url, headers=headers)\n",
        "    if resp.ok:\n",
        "        doc = extractor.get_content(resp.text)\n",
        "    else:\n",
        "        doc = get_body_from_soup(url)\n",
        "    testarticle = pd.DataFrame(columns=['title','body','label','url']) #header=None\n",
        "    title = 'news'\n",
        "    body = doc\n",
        "    label = 'fake'\n",
        "    url = url\n",
        "    testarticle = testarticle.append({'title': title, 'body': body, 'label': label,'url':url}, ignore_index=True)\n",
        "  except:\n",
        "    print(\"Please use different URL\")\n",
        "  return testarticle\n",
        "\n",
        "#if the above function fails, then use beautiful soup, just a check safe(its not used tho)\n",
        "def get_body_from_soup(url):\n",
        "  res = requests.get(url)\n",
        "  html_page = res.content\n",
        "  soup = BeautifulSoup(html_page, 'html.parser')\n",
        "  text = soup.find_all(text=True)\n",
        "  set([t.parent.name for t in text])\n",
        "  output = ''\n",
        "  want = ['body','title','p','div','article','h1','h2','h3','h4']\n",
        "  for t in text:\n",
        "      if t.parent.name in want:\n",
        "          output += '{} '.format(t)\n",
        "  return output\n",
        "\n",
        "def predict_article(url,model,model_roberta):\n",
        "    \n",
        "\n",
        "  url = url\n",
        "  testarticle = get_text_from_url(url)\n",
        "  # Extracting Dataset\n",
        "  testdataset = FakeNewsDataset(\n",
        "                            tokenizer=bert_tokenizer,\n",
        "                            min_len=MIN_LEN,\n",
        "                            max_len=MAX_LEN,\n",
        "                            chunk_len=CHUNK_LEN,\n",
        "                            max_size_dataset=1,\n",
        "                            overlap_len=OVERLAP_LEN,\n",
        "                            mode='test',\n",
        "                            testdf=testarticle\n",
        "                            )\n",
        "\n",
        "  test_data_loader=DataLoader(testdataset,\n",
        "                                batch_size=1,\n",
        "                                sampler=None,\n",
        "                                collate_fn=my_collate1)\n",
        "  num_training_steps = int(len(testdataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
        "  # Initializing/ loading Bert model trained before\n",
        "  model = model\n",
        "\n",
        "  #Loading all the layers of the bert model except the last one as explained in the class above.\n",
        "  model_roberta = model_robert\n",
        "  optimizer = AdamW(model_roberta.parameters(), lr=lr)\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                              num_warmup_steps=0,\n",
        "                                              num_training_steps=num_training_steps)\n",
        "  val_losses = []\n",
        "  output, target, val_losses_tmp = train_eval_robert_model(test_data_loader, model_roberta, optimizer, device,'eval')\n",
        "  y_pred = np.argmax(output, axis=1).flatten()[0] #Estimated targets as returned by a classifier.\n",
        "  pred_label = dict(map(reversed, dataset.label_mapping.items()))\n",
        "  \n",
        "  return pred_label[y_pred]\n",
        "\n",
        "# Check if Graphic card is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzNg8nTJsW16"
      },
      "source": [
        "## HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFCuL2G4r_Qb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "73f92d1ba15d441ea8f04647d446a5a0",
            "53db8bb00f3f4443ac716e0ae59014a3",
            "9bfd3a38652c4cc385cb12486d85cf05",
            "d7a7ede64be947a599b396d61207b4da",
            "28584ece32fe4a7faba766f28dd8cb8a",
            "6fea9648045d4cc999f35b3c39adaaaa",
            "8741d755a4744fbe8e24dc86cecc89c7",
            "1cbf17f018aa4007a50619af622046e6"
          ]
        },
        "outputId": "00236e89-5e67-4e4d-8909-3883a1a9d54c"
      },
      "source": [
        "TRAIN_BATCH_SIZE = 1\n",
        "DATASET_SPLIT = None\n",
        "shuffle_dataset = True\n",
        "random_seed = 42\n",
        "# MIN_LEN=249\n",
        "MIN_LEN = 10\n",
        "MAX_LEN = 50\n",
        "CHUNK_LEN = 200\n",
        "OVERLAP_LEN = 50\n",
        "max_size_dataset =None\n",
        "#max_size_dataset = 200\n",
        "NUM_CLASSES = 4\n",
        "lr = 1e-5\n",
        "file_location1=\"/content/Gdrive/MyDrive/covid19_news_dataset_train.csv\"\n",
        "file_location2=\"/content/drive/MyDrive/covid19_news_dataset_test.csv\"\n",
        "# Defining tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "#file_location = file_location1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73f92d1ba15d441ea8f04647d446a5a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOVPBbtzL_Oh"
      },
      "source": [
        "## Preparing Data For Training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViNAAmpDq0W_",
        "outputId": "a21fb60a-c192-4a2d-a089-0ea796e26e33"
      },
      "source": [
        "# Extracting Dataset for train_eval\n",
        "#file_location3=\"/content/Gdrive/MyDrive/covid19_news_dataset.csv\"\n",
        "dataset = FakeNewsDataset(file_location = file_location1,\n",
        "                          tokenizer=bert_tokenizer,\n",
        "                          min_len=MIN_LEN,\n",
        "                          max_len=MAX_LEN,\n",
        "                          chunk_len=CHUNK_LEN,\n",
        "                          max_size_dataset=max_size_dataset,\n",
        "                          overlap_len=OVERLAP_LEN,\n",
        "                          mode='train_eval',\n",
        "                          testdf=None\n",
        "                          )\n",
        "\n",
        "dataset_size = len(dataset)\n",
        "print('Total articles :' + str(dataset_size))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total articles :28557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni-oy0SRDL6u",
        "outputId": "534a42c3-bf76-4f5d-a458-2b512fc7618b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kef6Qn1Oqxe",
        "outputId": "d4eafa2b-ea07-43b5-d2ab-3bb03e96a63e"
      },
      "source": [
        "dataset.label_count\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "High probability true     13168\n",
              "High probability fake     12675\n",
              "fake                       1377\n",
              "true                       1337\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpewVgvcZNYF",
        "outputId": "c85cd1a8-9932-4407-fdc9-630458094745"
      },
      "source": [
        "dataset.label_count.plot.bar()\n",
        "plt.title('Label Distribution')\n",
        "plt.show()\n",
        "#test.groupby(['label']).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnQ0GwdOFBu2"
      },
      "source": [
        "# Because the labels are imbalanced, we split the data set in a stratified fashion, using this as the class labels.\n",
        "#Dividing into Train and Validating\n",
        "\n",
        "DATASET_SPLIT = .16\n",
        "train_idx, valid_idx = train_test_split(\n",
        "                                        np.arange(dataset_size),\n",
        "                                        test_size=DATASET_SPLIT,\n",
        "                                        shuffle=True,\n",
        "                                        stratify=dataset.label)\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "#Map-style datasets\n",
        "#A map-style dataset is one that implements the __getitem__() and __len__() protocols,\n",
        "# and represents a map from (possibly non-integral) indices/keys to data samples.\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "train_data_loader=DataLoader(\n",
        "                              dataset,\n",
        "                              batch_size=TRAIN_BATCH_SIZE,\n",
        "                              sampler=train_sampler,\n",
        "                              collate_fn=my_collate1)\n",
        "\n",
        "valid_data_loader=DataLoader(\n",
        "                              dataset,\n",
        "                              batch_size=TRAIN_BATCH_SIZE,\n",
        "                              sampler=valid_sampler,\n",
        "                              collate_fn=my_collate1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TctirL5FbR6l",
        "outputId": "2334c3d5-36b1-4a6e-b77f-a3bb90c8d999"
      },
      "source": [
        "train_classes = [dataset.label[i] for i in train_sampler.indices]\n",
        "validation_classes = [dataset.label[i] for i in valid_sampler.indices]\n",
        "import collections\n",
        "print(f'Number of labels in Training set are :{collections.Counter(train_classes)}') \n",
        "print(f'Number of labels in Validation set are :{collections.Counter(validation_classes)}') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels in Training set are :Counter({1: 11061, 0: 10646, 2: 1157, 3: 1123})\n",
            "Number of labels in Validation set are :Counter({1: 2107, 0: 2029, 2: 220, 3: 214})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjlvxYmxMIxU"
      },
      "source": [
        "## Preparing data For Testing (Done seperately because of some changes in last phase)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHtjew4UMIxV",
        "outputId": "9c618051-4272-414f-b943-5601ddd2dadd"
      },
      "source": [
        "# Extracting Dataset for train_eval\n",
        "#file_location = file_location2\n",
        "file_location2 = '/content/Gdrive/MyDrive/covid19_news_dataset_test.csv'\n",
        "dataset = FakeNewsDataset(file_location=file_location2,\n",
        "                          tokenizer=bert_tokenizer,\n",
        "                          min_len=MIN_LEN,\n",
        "                          max_len=MAX_LEN,\n",
        "                          chunk_len=CHUNK_LEN,\n",
        "                          max_size_dataset=max_size_dataset,\n",
        "                          overlap_len=OVERLAP_LEN,\n",
        "                          mode='train_eval',\n",
        "                          testdf=None\n",
        "                          )\n",
        "\n",
        "dataset_size = len(dataset)\n",
        "print('Total articles :' + str(dataset_size))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total articles :7132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAEpKfj5MIxV"
      },
      "source": [
        "#print(df.groupby(['label']).size())\n",
        "testindex = np.arange(len(dataset))\n",
        "test_sampler = SubsetRandomSampler(testindex)\n",
        "test_data_loader=DataLoader(\n",
        "                              dataset,\n",
        "                              batch_size=1,\n",
        "                              sampler=test_sampler,\n",
        "                              collate_fn=my_collate1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLgi0wGvCLim",
        "outputId": "8312f3c3-6163-4a82-958d-fcbe3d8890f6"
      },
      "source": [
        "test_classes = [dataset.label[i] for i in test_sampler.indices]\n",
        "\n",
        "import collections\n",
        "print(f'Number of labels in Test set are :{collections.Counter(test_classes)}') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels in Test set are :Counter({1: 3293, 0: 3165, 2: 342, 3: 332})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vFaoLLdsqVL"
      },
      "source": [
        "## Train Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW8Fcq-esJOB",
        "outputId": "8772255c-1fc4-4513-fc8a-6f511b138c4c"
      },
      "source": [
        "# Finetuning Data\n",
        "EPOCH = 1\n",
        "today = date.today()\n",
        "num_training_steps = int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
        "\n",
        "bert_model = model\n",
        "#bert_model = Bert_TextClassification_Model().to(device)\n",
        "# optimizer = SGD(model_hierarchical.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = AdamW(bert_model.parameters(), lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=num_training_steps)\n",
        "val_losses = []\n",
        "batches_losses = []\n",
        "val_acc = []\n",
        "for epoch in range(EPOCH):\n",
        "    # Training loop----------------------------------\n",
        "    t0 = time.time()\n",
        "    print(f\"\\n \\t Training Bert:  EPOCH {epoch + 1} / {EPOCH}\\n\")\n",
        "    batches_losses_tmp = train_eval_bert_model(train_data_loader, bert_model, optimizer, device,'train')\n",
        "    epoch_loss = np.mean(batches_losses_tmp)\n",
        "    print(\n",
        "        f\"\\n \\t avg_loss : {epoch_loss:.2f}, time : ~{(time.time() - t0)//3600} hour ({(time.time() - t0)//60} min) \\n\")\n",
        "    \n",
        "    #Evaluation loop---------------------------------\n",
        "    t1 = time.time()\n",
        "    output, target, val_losses_tmp = train_eval_bert_model(valid_data_loader, bert_model, optimizer, device, 'eval')\n",
        "    print(f\"\\n \\t Evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {(time.time() - t1)//60} min \\n\")\n",
        "    tmp_evaluate = evaluate(target.reshape(-1), output)\n",
        "\n",
        "  \t\n",
        "    # Predicting Accuracy-------------------------------\n",
        "    print(f\"\\t Accuracy = {tmp_evaluate['Accuracy']} \\n \\t No. of examples = {tmp_evaluate['No. of examples']}\\n\"\n",
        "          f\"\\t True prediction = {tmp_evaluate['True prediction']} \\n \\t False prediction = {tmp_evaluate['False prediction']} \\n\")\n",
        "  \n",
        "\n",
        "    val_acc.append(tmp_evaluate['Accuracy'])\n",
        "    val_losses.append(val_losses_tmp)\n",
        "    batches_losses.append(batches_losses_tmp)\n",
        "\n",
        "\n",
        "    #Saving model-------------------------------------\n",
        "    print(\"\\t Saving Bert model \")\n",
        "    torch.save(bert_model.state_dict(), f\"/content/Gdrive/My Drive/finetuned_BERT_Model-{today}-{epoch+1}.pt\")\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \t Training Bert:  EPOCH 1 / 1\n",
            "\n",
            "batch index = 0 / 28551 (0.00%), loss = 0.1377, time = 0.0 minutes \n",
            "batch index = 1000 / 28551 (3.50%), loss = 0.1287, time = 5.0 minutes \n",
            "batch index = 2000 / 28551 (7.01%), loss = 0.4291, time = 5.0 minutes \n",
            "batch index = 3000 / 28551 (10.51%), loss = 0.5301, time = 5.0 minutes \n",
            "batch index = 4000 / 28551 (14.01%), loss = 0.6784, time = 5.0 minutes \n",
            "batch index = 5000 / 28551 (17.51%), loss = 0.1869, time = 5.0 minutes \n",
            "batch index = 6000 / 28551 (21.02%), loss = 0.3092, time = 5.0 minutes \n",
            "batch index = 7000 / 28551 (24.52%), loss = 0.2186, time = 4.0 minutes \n",
            "batch index = 8000 / 28551 (28.02%), loss = 0.1023, time = 5.0 minutes \n",
            "batch index = 9000 / 28551 (31.52%), loss = 0.4336, time = 5.0 minutes \n",
            "batch index = 10000 / 28551 (35.03%), loss = 0.1608, time = 5.0 minutes \n",
            "batch index = 11000 / 28551 (38.53%), loss = 0.0734, time = 5.0 minutes \n",
            "batch index = 12000 / 28551 (42.03%), loss = 0.3219, time = 5.0 minutes \n",
            "batch index = 13000 / 28551 (45.53%), loss = 0.2043, time = 5.0 minutes \n",
            "batch index = 14000 / 28551 (49.04%), loss = 0.1022, time = 5.0 minutes \n",
            "batch index = 15000 / 28551 (52.54%), loss = 0.6125, time = 5.0 minutes \n",
            "batch index = 16000 / 28551 (56.04%), loss = 0.3697, time = 5.0 minutes \n",
            "batch index = 17000 / 28551 (59.54%), loss = 0.2959, time = 5.0 minutes \n",
            "batch index = 18000 / 28551 (63.05%), loss = 0.1829, time = 4.0 minutes \n",
            "batch index = 19000 / 28551 (66.55%), loss = 0.3500, time = 5.0 minutes \n",
            "batch index = 20000 / 28551 (70.05%), loss = 0.3273, time = 5.0 minutes \n",
            "batch index = 21000 / 28551 (73.55%), loss = 0.1857, time = 5.0 minutes \n",
            "batch index = 22000 / 28551 (77.06%), loss = 0.1535, time = 5.0 minutes \n",
            "batch index = 23000 / 28551 (80.56%), loss = 0.2069, time = 5.0 minutes \n",
            "batch index = 24000 / 28551 (84.06%), loss = 0.1716, time = 5.0 minutes \n",
            "batch index = 25000 / 28551 (87.56%), loss = 0.4130, time = 5.0 minutes \n",
            "batch index = 26000 / 28551 (91.07%), loss = 0.3076, time = 5.0 minutes \n",
            "batch index = 27000 / 28551 (94.57%), loss = 0.8005, time = 5.0 minutes \n",
            "batch index = 28000 / 28551 (98.07%), loss = 0.4146, time = 5.0 minutes \n",
            "\n",
            " \t avg_loss : 0.34, time : ~2.0 hour (148.0 min) \n",
            "\n",
            "\n",
            " \t Evaluation : avg_loss = 0.34, time : 9.0 min \n",
            "\n",
            "\t Accuracy = 0.8874777897527016 \n",
            " \t No. of examples = 34331\n",
            "\t True prediction = 30468 \n",
            " \t False prediction = 3863 \n",
            "\n",
            "\t Saving Bert model \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TGitx-XFZgX"
      },
      "source": [
        "## Train BERT-LSTM Hybrid Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxsbhXH8cZFa"
      },
      "source": [
        "model = Bert_TextClassification_Model()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/finetuned_BERT_Model-2021-03-03-1.pt'))\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5hYDN6lFZBI",
        "outputId": "07669ac0-f2b5-4dea-8327-ce1c3138fe42"
      },
      "source": [
        "# Latest\n",
        "'''\n",
        "# commenting this because I am not loading from the saved checkpoint\n",
        "model = Bert_TextClassification_Model()\n",
        "model.load_state_dict(torch.load('saved_Bert_Model1.pt'))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "'''\n",
        "EPOCH = 2\n",
        "today = date.today()\n",
        "num_training_steps = int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
        "# Initializing/ loading Bert model trained before\n",
        "model = model\n",
        "\n",
        "#Loading all the layers of the bert model except the last one as explained in the class above.\n",
        "#model_roberta = RoBERT_Model(bertFineTuned=list(model.children())[0]).to(device)\n",
        "model_roberta = model_robert\n",
        "optimizer = AdamW(model_roberta.parameters(), lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=num_training_steps)\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "batches_losses_train = []\n",
        "batches_losses_val = []\n",
        "val_acc = []\n",
        "train_acc = []\n",
        "for epoch in range(EPOCH):\n",
        "    # Training loop----------------------------------\n",
        "    t0 = time.time()\n",
        "    print(f\"\\n \\t Training Robert: EPOCH {epoch + 1} / {EPOCH} \\n\")\n",
        "    output, target, batches_losses_tmp = train_eval_robert_model(train_data_loader, model_roberta, optimizer, device,'train')\n",
        "    epoch_loss = np.mean(batches_losses_tmp)\n",
        "    print(\n",
        "        f\"\\n \\t avg_loss : {epoch_loss:.2f}, time : ~{(time.time() - t0) // 3600} hour ({(time.time() - t0) // 60} min)\\n\")\n",
        "    tmp_evaluate = evaluate(target.reshape(-1), output)\n",
        "\n",
        "    #Predicting accuracy------------------------------\n",
        "    print(f\"\\t Accuracy = {tmp_evaluate['Accuracy']} \\n \\t No. of examples = {tmp_evaluate['No. of examples']}\\n\"\n",
        "          f\"\\t True prediction = {tmp_evaluate['True prediction']} \\n \\t False prediction = {tmp_evaluate['False prediction']} \\n\")\n",
        "\n",
        "    train_acc.append(tmp_evaluate['Accuracy'])\n",
        "    train_losses.append(batches_losses_tmp)\n",
        "    #batches_losses_train.append(batches_losses_tmp)\n",
        "\n",
        "    \n",
        "    # Evaluation loop----------------------------------\n",
        "    t1 = time.time()\n",
        "    output, target, val_losses_tmp = train_eval_robert_model(valid_data_loader, model_roberta, optimizer, device,'eval')\n",
        "    print(f\"\\t  Evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {(time.time() - t1) // 60} min \\n\")\n",
        "    tmp_evaluate = evaluate(target.reshape(-1), output)\n",
        "\n",
        "    #Predicting accuracy------------------------------\n",
        "    print(f\"\\t Accuracy = {tmp_evaluate['Accuracy']} \\n \\t No. of examples = {tmp_evaluate['No. of examples']}\\n\"\n",
        "          f\"\\t True prediction = {tmp_evaluate['True prediction']} \\n \\t False prediction = {tmp_evaluate['False prediction']} \\n\")\n",
        "\n",
        "\n",
        "    val_acc.append(tmp_evaluate['Accuracy'])\n",
        "    val_losses.append(val_losses_tmp)\n",
        "    #batches_losses_val.append(batches_losses_tmp)\n",
        "\n",
        "    # Saving the model\n",
        "    print(\"\\t Saving Roberta model \")\n",
        "    #torch.save(model_roberta.state_dict(), f\"/content/Gdrive/My Drive/RoBERT_Model-{today}-{epoch+1}.pt\")\n",
        "    torch.save(model_roberta.state_dict(), f\"/content/drive/MyDrive/RoBERT_Model-{today}-{epoch+1}.pt\")\n",
        "\n",
        "    # ----------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \t Training Robert: EPOCH 1 / 2 \n",
            "\n",
            "batch index = 0 / 23987 (0.00%), loss = 0.0937, time = 0.0 minutes\n",
            "batch index = 1000 / 23987 (4.17%), loss = 0.0029, time = 5.0 minutes\n",
            "batch index = 2000 / 23987 (8.34%), loss = 0.3371, time = 5.0 minutes\n",
            "batch index = 3000 / 23987 (12.51%), loss = 0.0444, time = 4.0 minutes\n",
            "batch index = 4000 / 23987 (16.68%), loss = 0.2242, time = 5.0 minutes\n",
            "batch index = 5000 / 23987 (20.84%), loss = 0.1646, time = 4.0 minutes\n",
            "batch index = 6000 / 23987 (25.01%), loss = 0.2561, time = 4.0 minutes\n",
            "batch index = 7000 / 23987 (29.18%), loss = 0.0453, time = 4.0 minutes\n",
            "batch index = 8000 / 23987 (33.35%), loss = 0.7569, time = 5.0 minutes\n",
            "batch index = 9000 / 23987 (37.52%), loss = 0.1641, time = 4.0 minutes\n",
            "batch index = 10000 / 23987 (41.69%), loss = 0.0167, time = 5.0 minutes\n",
            "batch index = 11000 / 23987 (45.86%), loss = 0.1191, time = 4.0 minutes\n",
            "batch index = 12000 / 23987 (50.03%), loss = 0.0186, time = 4.0 minutes\n",
            "batch index = 13000 / 23987 (54.20%), loss = 0.4588, time = 5.0 minutes\n",
            "batch index = 14000 / 23987 (58.36%), loss = 0.0366, time = 5.0 minutes\n",
            "batch index = 15000 / 23987 (62.53%), loss = 0.1050, time = 5.0 minutes\n",
            "batch index = 16000 / 23987 (66.70%), loss = 0.0295, time = 5.0 minutes\n",
            "batch index = 17000 / 23987 (70.87%), loss = 0.2126, time = 5.0 minutes\n",
            "batch index = 18000 / 23987 (75.04%), loss = 0.0835, time = 5.0 minutes\n",
            "batch index = 19000 / 23987 (79.21%), loss = 0.5165, time = 5.0 minutes\n",
            "batch index = 20000 / 23987 (83.38%), loss = 0.0157, time = 5.0 minutes\n",
            "batch index = 21000 / 23987 (87.55%), loss = 0.0586, time = 5.0 minutes\n",
            "batch index = 22000 / 23987 (91.72%), loss = 0.1141, time = 5.0 minutes\n",
            "batch index = 23000 / 23987 (95.89%), loss = 0.4380, time = 5.0 minutes\n",
            "\n",
            " \t avg_loss : 0.14, time : ~2.0 hour (122.0 min)\n",
            "\n",
            "\t Accuracy = 0.9591028473756619 \n",
            " \t No. of examples = 23987\n",
            "\t True prediction = 23006 \n",
            " \t False prediction = 981 \n",
            "\n",
            "\t  Evaluation : avg_loss = 0.22, time : 5.0 min \n",
            "\n",
            "\t Accuracy = 0.9385120350109409 \n",
            " \t No. of examples = 4570\n",
            "\t True prediction = 4289 \n",
            " \t False prediction = 281 \n",
            "\n",
            "\t Saving Roberta model \n",
            "\n",
            " \t Training Robert: EPOCH 2 / 2 \n",
            "\n",
            "batch index = 0 / 23987 (0.00%), loss = 0.0011, time = 0.0 minutes\n",
            "batch index = 1000 / 23987 (4.17%), loss = 0.0748, time = 5.0 minutes\n",
            "batch index = 2000 / 23987 (8.34%), loss = 0.0929, time = 5.0 minutes\n",
            "batch index = 3000 / 23987 (12.51%), loss = 0.2284, time = 5.0 minutes\n",
            "batch index = 4000 / 23987 (16.68%), loss = 0.0354, time = 5.0 minutes\n",
            "batch index = 5000 / 23987 (20.84%), loss = 0.4309, time = 5.0 minutes\n",
            "batch index = 6000 / 23987 (25.01%), loss = 0.0114, time = 5.0 minutes\n",
            "batch index = 7000 / 23987 (29.18%), loss = 0.2427, time = 5.0 minutes\n",
            "batch index = 8000 / 23987 (33.35%), loss = 0.1212, time = 5.0 minutes\n",
            "batch index = 9000 / 23987 (37.52%), loss = 0.0304, time = 5.0 minutes\n",
            "batch index = 10000 / 23987 (41.69%), loss = 0.0181, time = 4.0 minutes\n",
            "batch index = 11000 / 23987 (45.86%), loss = 0.0052, time = 5.0 minutes\n",
            "batch index = 12000 / 23987 (50.03%), loss = 0.0031, time = 5.0 minutes\n",
            "batch index = 13000 / 23987 (54.20%), loss = 0.0246, time = 5.0 minutes\n",
            "batch index = 14000 / 23987 (58.36%), loss = 0.0097, time = 5.0 minutes\n",
            "batch index = 15000 / 23987 (62.53%), loss = 0.0180, time = 5.0 minutes\n",
            "batch index = 16000 / 23987 (66.70%), loss = 0.0482, time = 5.0 minutes\n",
            "batch index = 17000 / 23987 (70.87%), loss = 0.7874, time = 5.0 minutes\n",
            "batch index = 18000 / 23987 (75.04%), loss = 0.1423, time = 5.0 minutes\n",
            "batch index = 19000 / 23987 (79.21%), loss = 0.2817, time = 4.0 minutes\n",
            "batch index = 20000 / 23987 (83.38%), loss = 0.0151, time = 5.0 minutes\n",
            "batch index = 21000 / 23987 (87.55%), loss = 0.2125, time = 5.0 minutes\n",
            "batch index = 22000 / 23987 (91.72%), loss = 0.0081, time = 5.0 minutes\n",
            "batch index = 23000 / 23987 (95.89%), loss = 0.0641, time = 5.0 minutes\n",
            "\n",
            " \t avg_loss : 0.16, time : ~2.0 hour (123.0 min)\n",
            "\n",
            "\t Accuracy = 0.9554341935214908 \n",
            " \t No. of examples = 23987\n",
            "\t True prediction = 22918 \n",
            " \t False prediction = 1069 \n",
            "\n",
            "\t  Evaluation : avg_loss = 0.16, time : 5.0 min \n",
            "\n",
            "\t Accuracy = 0.9614879649890591 \n",
            " \t No. of examples = 4570\n",
            "\t True prediction = 4394 \n",
            " \t False prediction = 176 \n",
            "\n",
            "\t Saving Roberta model \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtqmM9oMknNn",
        "outputId": "ddfa6fde-ebca-42e7-f626-232b0602d4f8"
      },
      "source": [
        "EPOCH = 2\n",
        "today = date.today()\n",
        "num_training_steps = int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
        "# Initializing/ loading Bert model trained before\n",
        "model = model\n",
        "\n",
        "#Loading all the layers of the bert model except the last one as explained in the class above.\n",
        "#model_roberta = RoBERT_Model(bertFineTuned=list(model.children())[0]).to(device)\n",
        "model_roberta = model_roberta\n",
        "optimizer = AdamW(model_roberta.parameters(), lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=num_training_steps)\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "batches_losses_train = []\n",
        "batches_losses_val = []\n",
        "val_acc = []\n",
        "train_acc = []\n",
        "for epoch in range(EPOCH):\n",
        "    # Training loop----------------------------------\n",
        "    t0 = time.time()\n",
        "    print(f\"\\n \\t Training Robert: EPOCH {epoch + 1} / {EPOCH} \\n\")\n",
        "    output, target, batches_losses_tmp = train_eval_robert_model(train_data_loader, model_roberta, optimizer, device,'train')\n",
        "    epoch_loss = np.mean(batches_losses_tmp)\n",
        "    print(\n",
        "        f\"\\n \\t avg_loss : {epoch_loss:.2f}, time : ~{(time.time() - t0) // 3600} hour ({(time.time() - t0) // 60} min)\\n\")\n",
        "    tmp_evaluate = evaluate(target.reshape(-1), output)\n",
        "\n",
        "    #Predicting accuracy------------------------------\n",
        "    print(f\"\\t Accuracy = {tmp_evaluate['Accuracy']} \\n \\t No. of examples = {tmp_evaluate['No. of examples']}\\n\"\n",
        "          f\"\\t True prediction = {tmp_evaluate['True prediction']} \\n \\t False prediction = {tmp_evaluate['False prediction']} \\n\")\n",
        "\n",
        "    train_acc.append(tmp_evaluate['Accuracy'])\n",
        "    train_losses.append(batches_losses_tmp)\n",
        "    #batches_losses_train.append(batches_losses_tmp)\n",
        "\n",
        "    \n",
        "    # Evaluation loop----------------------------------\n",
        "    t1 = time.time()\n",
        "    output, target, val_losses_tmp = train_eval_robert_model(valid_data_loader, model_roberta, optimizer, device,'eval')\n",
        "    print(f\"\\t  Evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {(time.time() - t1) // 60} min \\n\")\n",
        "    tmp_evaluate = evaluate(target.reshape(-1), output)\n",
        "\n",
        "    #Predicting accuracy------------------------------\n",
        "    print(f\"\\t Accuracy = {tmp_evaluate['Accuracy']} \\n \\t No. of examples = {tmp_evaluate['No. of examples']}\\n\"\n",
        "          f\"\\t True prediction = {tmp_evaluate['True prediction']} \\n \\t False prediction = {tmp_evaluate['False prediction']} \\n\")\n",
        "\n",
        "\n",
        "    val_acc.append(tmp_evaluate['Accuracy'])\n",
        "    val_losses.append(val_losses_tmp)\n",
        "    #batches_losses_val.append(batches_losses_tmp)\n",
        "\n",
        "    # Saving the model\n",
        "    print(\"\\t Saving Roberta model \")\n",
        "    #torch.save(model_roberta.state_dict(), f\"/content/Gdrive/My Drive/RoBERT_Model-{today}-{epoch+1}.pt\")\n",
        "    torch.save(model_roberta.state_dict(), f\"/content/drive/MyDrive/RoBERT_Model-{today}-{epoch+1}.pt\")\n",
        "\n",
        "    # ----------------\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \t Training Robert: EPOCH 1 / 2 \n",
            "\n",
            "batch index = 0 / 23987 (0.00%), loss = 1.1341, time = 0.0 minutes\n",
            "batch index = 1000 / 23987 (4.17%), loss = 1.1864, time = 4.0 minutes\n",
            "batch index = 2000 / 23987 (8.34%), loss = 0.4006, time = 4.0 minutes\n",
            "batch index = 3000 / 23987 (12.51%), loss = 0.4653, time = 4.0 minutes\n",
            "batch index = 4000 / 23987 (16.68%), loss = 0.3271, time = 4.0 minutes\n",
            "batch index = 5000 / 23987 (20.84%), loss = 0.0322, time = 4.0 minutes\n",
            "batch index = 6000 / 23987 (25.01%), loss = 0.0134, time = 4.0 minutes\n",
            "batch index = 7000 / 23987 (29.18%), loss = 0.4176, time = 4.0 minutes\n",
            "batch index = 8000 / 23987 (33.35%), loss = 0.0195, time = 4.0 minutes\n",
            "batch index = 9000 / 23987 (37.52%), loss = 0.0334, time = 4.0 minutes\n",
            "batch index = 10000 / 23987 (41.69%), loss = 0.8658, time = 4.0 minutes\n",
            "batch index = 11000 / 23987 (45.86%), loss = 0.3532, time = 4.0 minutes\n",
            "batch index = 12000 / 23987 (50.03%), loss = 0.0369, time = 4.0 minutes\n",
            "batch index = 13000 / 23987 (54.20%), loss = 0.0210, time = 4.0 minutes\n",
            "batch index = 14000 / 23987 (58.36%), loss = 0.5737, time = 4.0 minutes\n",
            "batch index = 15000 / 23987 (62.53%), loss = 0.0151, time = 4.0 minutes\n",
            "batch index = 16000 / 23987 (66.70%), loss = 0.0903, time = 4.0 minutes\n",
            "batch index = 17000 / 23987 (70.87%), loss = 0.2720, time = 4.0 minutes\n",
            "batch index = 18000 / 23987 (75.04%), loss = 0.0108, time = 4.0 minutes\n",
            "batch index = 19000 / 23987 (79.21%), loss = 0.0381, time = 4.0 minutes\n",
            "batch index = 20000 / 23987 (83.38%), loss = 0.2581, time = 4.0 minutes\n",
            "batch index = 21000 / 23987 (87.55%), loss = 0.0099, time = 4.0 minutes\n",
            "batch index = 22000 / 23987 (91.72%), loss = 0.5748, time = 4.0 minutes\n",
            "batch index = 23000 / 23987 (95.89%), loss = 0.0311, time = 4.0 minutes\n",
            "\n",
            " \t avg_loss : 0.14, time : ~1.0 hour (115.0 min)\n",
            "\n",
            "\t Accuracy = 0.9591862258723475 \n",
            " \t No. of examples = 23987\n",
            "\t True prediction = 23008 \n",
            " \t False prediction = 979 \n",
            "\n",
            "\t  Evaluation : avg_loss = 0.31, time : 5.0 min \n",
            "\n",
            "\t Accuracy = 0.9205689277899344 \n",
            " \t No. of examples = 4570\n",
            "\t True prediction = 4207 \n",
            " \t False prediction = 363 \n",
            "\n",
            "\t Saving Roberta model \n",
            "\n",
            " \t Training Robert: EPOCH 2 / 2 \n",
            "\n",
            "batch index = 0 / 23987 (0.00%), loss = 0.0236, time = 0.0 minutes\n",
            "batch index = 1000 / 23987 (4.17%), loss = 0.0303, time = 4.0 minutes\n",
            "batch index = 2000 / 23987 (8.34%), loss = 0.0178, time = 4.0 minutes\n",
            "batch index = 3000 / 23987 (12.51%), loss = 0.0718, time = 4.0 minutes\n",
            "batch index = 4000 / 23987 (16.68%), loss = 0.0911, time = 4.0 minutes\n",
            "batch index = 5000 / 23987 (20.84%), loss = 0.0204, time = 4.0 minutes\n",
            "batch index = 6000 / 23987 (25.01%), loss = 0.2313, time = 4.0 minutes\n",
            "batch index = 7000 / 23987 (29.18%), loss = 0.0210, time = 4.0 minutes\n",
            "batch index = 8000 / 23987 (33.35%), loss = 0.0181, time = 4.0 minutes\n",
            "batch index = 9000 / 23987 (37.52%), loss = 0.0179, time = 4.0 minutes\n",
            "batch index = 10000 / 23987 (41.69%), loss = 0.1482, time = 4.0 minutes\n",
            "batch index = 11000 / 23987 (45.86%), loss = 0.5531, time = 4.0 minutes\n",
            "batch index = 12000 / 23987 (50.03%), loss = 0.6285, time = 4.0 minutes\n",
            "batch index = 13000 / 23987 (54.20%), loss = 0.0314, time = 4.0 minutes\n",
            "batch index = 14000 / 23987 (58.36%), loss = 0.0056, time = 4.0 minutes\n",
            "batch index = 15000 / 23987 (62.53%), loss = 0.1685, time = 4.0 minutes\n",
            "batch index = 16000 / 23987 (66.70%), loss = 0.2039, time = 5.0 minutes\n",
            "batch index = 17000 / 23987 (70.87%), loss = 0.8029, time = 4.0 minutes\n",
            "batch index = 18000 / 23987 (75.04%), loss = 0.1912, time = 4.0 minutes\n",
            "batch index = 19000 / 23987 (79.21%), loss = 0.0177, time = 4.0 minutes\n",
            "batch index = 20000 / 23987 (83.38%), loss = 0.0319, time = 5.0 minutes\n",
            "batch index = 21000 / 23987 (87.55%), loss = 0.4833, time = 4.0 minutes\n",
            "batch index = 22000 / 23987 (91.72%), loss = 0.0223, time = 4.0 minutes\n",
            "batch index = 23000 / 23987 (95.89%), loss = 0.0562, time = 4.0 minutes\n",
            "\n",
            " \t avg_loss : 0.13, time : ~1.0 hour (115.0 min)\n",
            "\n",
            "\t Accuracy = 0.9617292700212615 \n",
            " \t No. of examples = 23987\n",
            "\t True prediction = 23069 \n",
            " \t False prediction = 918 \n",
            "\n",
            "\t  Evaluation : avg_loss = 0.16, time : 5.0 min \n",
            "\n",
            "\t Accuracy = 0.9566739606126915 \n",
            " \t No. of examples = 4570\n",
            "\t True prediction = 4372 \n",
            " \t False prediction = 198 \n",
            "\n",
            "\t Saving Roberta model \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLYKTrzJdfEt",
        "outputId": "9202bc25-f992-463e-b198-19bf728743c6"
      },
      "source": [
        "EPOCH = 2\n",
        "today = date.today()\n",
        "num_training_steps = int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
        "# Initializing/ loading Bert model trained before\n",
        "model = model\n",
        "\n",
        "#Loading all the layers of the bert model except the last one as explained in the class above.\n",
        "#model_roberta = RoBERT_Model(bertFineTuned=list(model.children())[0]).to(device)\n",
        "model_roberta = model_robert\n",
        "optimizer = AdamW(model_roberta.parameters(), lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=num_training_steps)\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "batches_losses_train = []\n",
        "batches_losses_val = []\n",
        "val_acc = []\n",
        "train_acc = []\n",
        "for epoch in range(EPOCH):\n",
        "    # Training loop----------------------------------\n",
        "    t0 = time.time()\n",
        "    print(f\"\\n \\t Training Robert: EPOCH {epoch + 1} / {EPOCH} \\n\")\n",
        "    output, target, batches_losses_tmp = train_eval_robert_model(train_data_loader, model_roberta, optimizer, device,'train')\n",
        "    epoch_loss = np.mean(batches_losses_tmp)\n",
        "    print(\n",
        "        f\"\\n \\t avg_loss : {epoch_loss:.2f}, time : ~{(time.time() - t0) // 3600} hour ({(time.time() - t0) // 60} min)\\n\")\n",
        "    tmp_evaluate = evaluate(target.reshape(-1), output)\n",
        "\n",
        "    #Predicting accuracy------------------------------\n",
        "    print(f\"\\t Accuracy = {tmp_evaluate['Accuracy']} \\n \\t No. of examples = {tmp_evaluate['No. of examples']}\\n\"\n",
        "          f\"\\t True prediction = {tmp_evaluate['True prediction']} \\n \\t False prediction = {tmp_evaluate['False prediction']} \\n\")\n",
        "\n",
        "    train_acc.append(tmp_evaluate['Accuracy'])\n",
        "    train_losses.append(batches_losses_tmp)\n",
        "    #batches_losses_train.append(batches_losses_tmp)\n",
        "\n",
        "    \n",
        "    # Evaluation loop----------------------------------\n",
        "    t1 = time.time()\n",
        "    output, target, val_losses_tmp = train_eval_robert_model(valid_data_loader, model_roberta, optimizer, device,'eval')\n",
        "    print(f\"\\t  Evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {(time.time() - t1) // 60} min \\n\")\n",
        "    tmp_evaluate = evaluate(target.reshape(-1), output)\n",
        "\n",
        "    #Predicting accuracy------------------------------\n",
        "    print(f\"\\t Accuracy = {tmp_evaluate['Accuracy']} \\n \\t No. of examples = {tmp_evaluate['No. of examples']}\\n\"\n",
        "          f\"\\t True prediction = {tmp_evaluate['True prediction']} \\n \\t False prediction = {tmp_evaluate['False prediction']} \\n\")\n",
        "\n",
        "\n",
        "    val_acc.append(tmp_evaluate['Accuracy'])\n",
        "    val_losses.append(val_losses_tmp)\n",
        "    #batches_losses_val.append(batches_losses_tmp)\n",
        "\n",
        "    # Saving the model\n",
        "    print(\"\\t Saving Roberta model \")\n",
        "    #torch.save(model_roberta.state_dict(), f\"/content/Gdrive/My Drive/RoBERT_Model-{today}-{epoch+1}.pt\")\n",
        "    torch.save(model_roberta.state_dict(), f\"/content/drive/MyDrive/RoBERT_Model-{today}-{epoch+1}.pt\")\n",
        "\n",
        "    # ----------------\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \t Training Robert: EPOCH 1 / 2 \n",
            "\n",
            "batch index = 0 / 23987 (0.00%), loss = 0.1761, time = 0.0 minutes\n",
            "batch index = 1000 / 23987 (4.17%), loss = 0.0142, time = 8.0 minutes\n",
            "batch index = 2000 / 23987 (8.34%), loss = 0.0863, time = 8.0 minutes\n",
            "batch index = 3000 / 23987 (12.51%), loss = 0.3922, time = 8.0 minutes\n",
            "batch index = 4000 / 23987 (16.68%), loss = 0.0592, time = 8.0 minutes\n",
            "batch index = 5000 / 23987 (20.84%), loss = 0.5011, time = 9.0 minutes\n",
            "batch index = 6000 / 23987 (25.01%), loss = 0.0210, time = 8.0 minutes\n",
            "batch index = 7000 / 23987 (29.18%), loss = 0.1459, time = 9.0 minutes\n",
            "batch index = 8000 / 23987 (33.35%), loss = 0.0202, time = 8.0 minutes\n",
            "batch index = 9000 / 23987 (37.52%), loss = 0.0080, time = 8.0 minutes\n",
            "batch index = 10000 / 23987 (41.69%), loss = 0.0624, time = 8.0 minutes\n",
            "batch index = 11000 / 23987 (45.86%), loss = 0.2910, time = 8.0 minutes\n",
            "batch index = 12000 / 23987 (50.03%), loss = 0.2967, time = 9.0 minutes\n",
            "batch index = 13000 / 23987 (54.20%), loss = 0.5721, time = 8.0 minutes\n",
            "batch index = 14000 / 23987 (58.36%), loss = 0.3487, time = 8.0 minutes\n",
            "batch index = 15000 / 23987 (62.53%), loss = 0.0278, time = 9.0 minutes\n",
            "batch index = 16000 / 23987 (66.70%), loss = 0.4562, time = 9.0 minutes\n",
            "batch index = 17000 / 23987 (70.87%), loss = 0.3025, time = 8.0 minutes\n",
            "batch index = 18000 / 23987 (75.04%), loss = 0.0299, time = 9.0 minutes\n",
            "batch index = 19000 / 23987 (79.21%), loss = 0.5330, time = 8.0 minutes\n",
            "batch index = 20000 / 23987 (83.38%), loss = 0.0813, time = 8.0 minutes\n",
            "batch index = 21000 / 23987 (87.55%), loss = 0.0387, time = 9.0 minutes\n",
            "batch index = 22000 / 23987 (91.72%), loss = 0.1056, time = 8.0 minutes\n",
            "batch index = 23000 / 23987 (95.89%), loss = 0.0788, time = 9.0 minutes\n",
            "\n",
            " \t avg_loss : 0.18, time : ~3.0 hour (214.0 min)\n",
            "\n",
            "\t Accuracy = 0.952265810647434 \n",
            " \t No. of examples = 23987\n",
            "\t True prediction = 22842 \n",
            " \t False prediction = 1145 \n",
            "\n",
            "\t  Evaluation : avg_loss = 0.34, time : 10.0 min \n",
            "\n",
            "\t Accuracy = 0.9111597374179431 \n",
            " \t No. of examples = 4570\n",
            "\t True prediction = 4164 \n",
            " \t False prediction = 406 \n",
            "\n",
            "\t Saving Roberta model \n",
            "\n",
            " \t Training Robert: EPOCH 2 / 2 \n",
            "\n",
            "batch index = 0 / 23987 (0.00%), loss = 0.0368, time = 0.0 minutes\n",
            "batch index = 1000 / 23987 (4.17%), loss = 0.0485, time = 8.0 minutes\n",
            "batch index = 2000 / 23987 (8.34%), loss = 0.0481, time = 8.0 minutes\n",
            "batch index = 3000 / 23987 (12.51%), loss = 0.1613, time = 8.0 minutes\n",
            "batch index = 4000 / 23987 (16.68%), loss = 0.0096, time = 8.0 minutes\n",
            "batch index = 5000 / 23987 (20.84%), loss = 0.0148, time = 9.0 minutes\n",
            "batch index = 6000 / 23987 (25.01%), loss = 0.1522, time = 9.0 minutes\n",
            "batch index = 7000 / 23987 (29.18%), loss = 0.7629, time = 9.0 minutes\n",
            "batch index = 8000 / 23987 (33.35%), loss = 0.0189, time = 8.0 minutes\n",
            "batch index = 9000 / 23987 (37.52%), loss = 0.5427, time = 9.0 minutes\n",
            "batch index = 10000 / 23987 (41.69%), loss = 0.0179, time = 8.0 minutes\n",
            "batch index = 11000 / 23987 (45.86%), loss = 0.0181, time = 9.0 minutes\n",
            "batch index = 12000 / 23987 (50.03%), loss = 0.1129, time = 9.0 minutes\n",
            "batch index = 13000 / 23987 (54.20%), loss = 0.0118, time = 9.0 minutes\n",
            "batch index = 14000 / 23987 (58.36%), loss = 0.2594, time = 9.0 minutes\n",
            "batch index = 15000 / 23987 (62.53%), loss = 0.0242, time = 9.0 minutes\n",
            "batch index = 16000 / 23987 (66.70%), loss = 0.1129, time = 9.0 minutes\n",
            "batch index = 17000 / 23987 (70.87%), loss = 0.1501, time = 8.0 minutes\n",
            "batch index = 18000 / 23987 (75.04%), loss = 0.0415, time = 8.0 minutes\n",
            "batch index = 19000 / 23987 (79.21%), loss = 0.0554, time = 8.0 minutes\n",
            "batch index = 20000 / 23987 (83.38%), loss = 0.1039, time = 9.0 minutes\n",
            "batch index = 21000 / 23987 (87.55%), loss = 0.0595, time = 8.0 minutes\n",
            "batch index = 22000 / 23987 (91.72%), loss = 0.1697, time = 9.0 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TUQS2AmbFa0"
      },
      "source": [
        "## Check Parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wStn7dE7bI5t"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model_roberta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr0Vwb_cnIsa"
      },
      "source": [
        "## Check Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpuwOpBCIPFR"
      },
      "source": [
        "y_pred = np.argmax(output, axis=1).flatten() #Estimated targets as returned by a classifier.\n",
        "y_test = target #Ground truth (correct) target values."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6iuPVTIuOtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e1a2ad-2818-4c1a-c03a-846200be032b"
      },
      "source": [
        "dataset.label_count.index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['High probability true', 'High probability fake ', 'fake', 'true'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNtH6iYMH4FF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "6398a383-62a5-42a2-fd23-e492f2e38aab"
      },
      "source": [
        "#calculate confusion matrix\n",
        "#cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1,2,3])\n",
        "\n",
        "#calculate Precision and recall from Conf_matrix\n",
        "tp = np.diag(cnf_matrix)\n",
        "prec = list(map(truediv, tp, np.sum(cnf_matrix, axis=0)))\n",
        "rec = list(map(truediv, tp, np.sum(cnf_matrix, axis=1)))\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "plot_confusion_matrix(cnf_matrix, classes=dataset.label_count.index,title='Confusion matrix, without normalization')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ufMJAEGdLCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8033fc3c-0e0f-4f62-86bf-fa682f92e4c0"
      },
      "source": [
        "get_f1_precision_recall(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: [0.96 0.96 0.85 0.88]\n",
            "recall   : [0.94 1.00 0.61 0.92]\n",
            "fscore   : [0.95 0.98 0.71 0.90]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cInLjRhStUKA"
      },
      "source": [
        "## Load Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbFJozZQxBBy"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le3dZNFztW3r"
      },
      "source": [
        "model = Bert_TextClassification_Model()\n",
        "model.load_state_dict(torch.load('/content/Gdrive/MyDrive/finetuned_BERT_Model-2020-12-14-2.pt'))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "file_location3 = '/content/Gdrive/MyDrive/recovery-news-data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDxZFnb7vTLQ"
      },
      "source": [
        "model_robert = RoBERT_Model(bertFineTuned=list(model.children())[0]).to(device)\n",
        "model_robert.load_state_dict(torch.load('/content/Gdrive/MyDrive/RoBERT_Model-2021-02-15-2.pt'))\n",
        "model_robert.to(device)\n",
        "model_robert.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8XdKdnig7i2"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model_robert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coWYZc7IsVgB"
      },
      "source": [
        "## Predict test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fifg8K-THfm0"
      },
      "source": [
        "url = 'https://www.who.int/news-room/detail/08-04-2020-strengthening-accountability-to-end-tb'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQjSeMMWSkpz"
      },
      "source": [
        "predict_article(url,model=model,model_roberta=model_robert)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}